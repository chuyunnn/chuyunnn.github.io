<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>WIRE-Wavelet Implicit Neural Representations | CYun's</title><meta name="author" content="chuyun deng"><meta name="copyright" content="chuyun deng"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="SIREN使用的是纯正弦函数，虽然能捕捉高频，但在空间（或时间）上的局部性较差。WIRE引入了复数Gabor小波 (Complex Gabor Wavelet)激活函数 &#x3D;&#x3D;&gt; 在空间域和频率域都具有紧凑性（即同时具备局部性和频率选择性） code：https:&#x2F;&#x2F;vishwa91.github.io&#x2F;wire author：Vishwanath Saragadam, D">
<meta property="og:type" content="article">
<meta property="og:title" content="WIRE-Wavelet Implicit Neural Representations">
<meta property="og:url" content="https://chuyunnn.github.io/papers/work1/WIRE-Wavelet-Implicit-Neural-Representations/index.html">
<meta property="og:site_name" content="CYun&#39;s">
<meta property="og:description" content="SIREN使用的是纯正弦函数，虽然能捕捉高频，但在空间（或时间）上的局部性较差。WIRE引入了复数Gabor小波 (Complex Gabor Wavelet)激活函数 &#x3D;&#x3D;&gt; 在空间域和频率域都具有紧凑性（即同时具备局部性和频率选择性） code：https:&#x2F;&#x2F;vishwa91.github.io&#x2F;wire author：Vishwanath Saragadam, D">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://chuyunnn.github.io/img/butterfly-icon.png">
<meta property="article:published_time" content="2026-01-26T07:34:41.000Z">
<meta property="article:modified_time" content="2026-01-26T08:27:42.396Z">
<meta property="article:author" content="chuyun deng">
<meta property="article:tag" content="INR">
<meta property="article:tag" content="SR">
<meta property="article:tag" content="papers">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://chuyunnn.github.io/img/butterfly-icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "WIRE-Wavelet Implicit Neural Representations",
  "url": "https://chuyunnn.github.io/papers/work1/WIRE-Wavelet-Implicit-Neural-Representations/",
  "image": "https://chuyunnn.github.io/img/butterfly-icon.png",
  "datePublished": "2026-01-26T07:34:41.000Z",
  "dateModified": "2026-01-26T08:27:42.396Z",
  "author": [
    {
      "@type": "Person",
      "name": "chuyun deng",
      "url": "https://chuyunnn.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://chuyunnn.github.io/papers/work1/WIRE-Wavelet-Implicit-Neural-Representations/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.5.3"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'WIRE-Wavelet Implicit Neural Representations',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">CYun's</span></a><a class="nav-page-title" href="/"><span class="site-name">WIRE-Wavelet Implicit Neural Representations</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">WIRE-Wavelet Implicit Neural Representations</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2026-01-26T07:34:41.000Z" title="Created 2026-01-26 15:34:41">2026-01-26</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2026-01-26T08:27:42.396Z" title="Updated 2026-01-26 16:27:42">2026-01-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/papers/">papers</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/papers/work1/">work1</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>SIREN使用的是纯正弦函数，虽然能捕捉高频，但在空间（或时间）上的局部性较差。WIRE引入了<strong>复数Gabor小波 (Complex Gabor Wavelet)激活函数</strong></p>
<p>&#x3D;&#x3D;&gt; 在空间域和频率域都具有紧凑性（即同时具备局部性和频率选择性）</p>
<p>code：<a target="_blank" rel="noopener" href="https://vishwa91.github.io/wire">https://vishwa91.github.io/wire</a></p>
<p>author：Vishwanath Saragadam, Daniel LeJeune, Jasper Tan, Guha Balakrishnan, Ashok Veeraraghavan, Richard G. Baraniuk</p>
<p><code>Rice University</code></p>
<p><code>CVPR 2023</code></p>
<p>📖 内容：</p>
<p>[TOC]</p>
<h1 id="abstruct"><a href="#abstruct" class="headerlink" title="abstruct"></a>abstruct</h1><p>隐性神经表征（INR）近年来在众多视觉相关领域取得了进展。INR的性能高度依赖于**<u>其MLP网络中激活函数的选择</u><strong>。虽然探索了多种非线性，但遗憾的是，当前设计的</strong>高准确度INR<strong>也存在</strong>鲁棒性较差**（对信号噪声、参数变异等）。受谐波分析启发，我们开发了一种新的高精度且稳健的INR，不存在这种权衡。</p>
<p>我们的小波隐式神经再表征（WIRE）激活函数是<strong>复Gabor小波</strong>，该小波已知在空间频率中最优集中，且在图像表现上具有优异的偏置。一系列实验（<u>图像去噪、图像修复、超分辨率、计算机断层重建、图像过拟合以及神经辐射场新颖视图合成</u>）证明WIRE在INR准确性、训练时间和鲁棒性方面达到了新技术水平。</p>
<h1 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h1><p>隐式神经表征（INR）能够在一组点上学习连续函数，已成为一种有前景的通用信号处理框架。INR由多层感知器（MLP）组成，结合了线性层和元素级非线性激活函数。得益于MLP，INR<strong>不存在限制卷积神经网络（CNN）性能的局部偏差</strong>。因此，INR在多个视觉相关领域取得了进步，包括计算机图形学[22， 27， 28]、图像处理[10]、逆问题[42]和信号表示[41]。</p>
<p>目前，INR仍面临许多限制其使用的障碍。首先，对于高维数据如三维体积的应用，<em><strong>训练高精度INR仍可能耗时过长（数十秒）</strong></em>，用于实时应用。其次，INR<em><strong>对信号噪声不够稳健或测量不足</strong></em>。事实上，大多数关于点燃暴露INR的<em><strong>研究假设几乎没有信号噪声且数据量大</strong></em>。我们自身实验发现，当前INR方法<em><strong>在去噪或超分辨率等任务中效果有限</strong></em>。最后，INR在<em><strong>细节表现精度方面</strong></em>仍有提升空间。</p>
<p>本文开发了一种**<u>新的、更快、更准确且稳健</u><strong>的INR，解决这些问题，并将INR性能提升到新高度。为此，我们从</strong>谐波分析**中汲取灵感，重新考虑MLP中使用的非线性激活函数。最新研究表明，INR可以被解释为结构化信号表示词典[51]，其中激活非线性决定词典的原子。例如，正弦激活创造了一个伪傅里叶变换表示，使信号在频域中最大集中[51]。</p>
<p>从过去四十年的调和分析研究中可以得出一个重要结论：傅里叶方法对于表现典型视觉任务中出现的信号类型并不理想[24]。这类信号，例如照片中的自然图像，通过在空间频率中最优集中的小波原子，可以更简洁、更稳健地表示。小波原子的稀疏组成已知在图像表现上具有极佳的偏置;参见计算机视觉领域的开创性工作（如拉普拉斯金字塔）、计算神经科学[30]以及JPEG2000压缩标准。</p>
<blockquote>
<p>[!NOTE]</p>
<p>傅里叶变换不太适合处理图像这类现实世界的信号，而小波更适合，因为它能把图像表示得更 “紧凑”、更稳定</p>
<p>它把信号看成<strong>不同频率的正弦波叠加</strong>，而正弦波是<strong>在整个空间无限延伸</strong>的，没有 “位置” 概念</p>
<ul>
<li>但是图像里的信息往往是<strong>局部的</strong>：边缘、纹理都集中在某些区域，而不是均匀分布在整张图的频率里</li>
</ul>
<p>因此傅里叶变换擅长处理<strong>平稳、全局规律明显</strong>的信号（比如纯音、周期性波形）</p>
<p>🌟 对<strong>局部突变多、结构复杂</strong>的图像，它的表示会比较 “啰嗦”，也不够稳健（噪声、局部变化都会让频谱变得很难看）</p>
<hr>
<p>小波（wavelet）可以理解成一些<strong>在空间上有限、在频率上也比较集中</strong>的小波形，通过<strong>平移 + 缩放</strong>这些小波，可以覆盖图像的不同位置、不同尺度（大小）、不同方向</p>
<ul>
<li><strong>局部性好</strong>：某个小波主要对应图像中某个位置附近的结构</li>
<li><strong>多尺度</strong>：<u>大尺度小波</u>看整体轮廓，<u>小尺度小波</u>看细节、纹理</li>
<li>能把图像分解成<strong>少数几个重要小波系数 + 很多接近零的系数</strong>，也就是所谓的<strong>稀疏组成</strong></li>
</ul>
<p>小波（以及后来的各种<strong>稀疏表示、字典学习</strong>方法）更适合作为图像的 “表示基础”，因为更符合人类视觉：我们对<strong>边缘、纹理</strong>这些结构敏感，而小波正好擅长捕捉这些</p>
</blockquote>
<p>在本文中，我们介绍了小波隐式神经表示(WIRE)，这是一种基于<em><strong>复Gabor小波激活函数的新的INR</strong></em>(见图1)。</p>
<p>通过广泛的实验，我们证明了WIRE在INR精度、训练时间和稳健性方面定义了新的艺术状态。</p>
<p>我们展示了WIRE增强的稳健性对于解决困难的<u>视觉逆问题</u>特别有用，包括</p>
<p>图像去噪(稳健性)、图像修复和超分辨率(优越内插)以及2D计算机断层扫描(CT)重建(解决更高维逆问题)。</p>
<p>Wire在信号表示任务方面也优于其他INR，例如过拟合图像和学习点云占有量。</p>
<p>最后，我们展示了WIRE能够从非常少的训练视图中用神经辐射场(NERF)[27]实现更快、更健壮的新视图合成。</p>
<h1 id="prior-work"><a href="#prior-work" class="headerlink" title="prior work"></a>prior work</h1><h2 id="Regularization-for-inverse-problems-逆问题的正则化"><a href="#Regularization-for-inverse-problems-逆问题的正则化" class="headerlink" title="Regularization for inverse problems. 逆问题的正则化"></a>Regularization for inverse problems. 逆问题的正则化</h2><p>逆问题涉及从<u>线性或非线性</u>测量集估计信号。不可避免地，测量结果会被噪声（如相机读出或光子噪声）影响，或者问题条件不良，需要正则化。正则化有多种形式，包括脊回归、套索法[45]、全变差（TV）[9]以及基于稀疏度的[7]技术，这些技术旨在惩罚信号的l1范数或其某种变换。过去十年中，数据驱动正则化技术，包括基于过完备的字典[4]和基于生成网络的[29， 35， 36]技术被开发出来。经典基于模型的方法对于<u>严重条件不良的问题不够用</u>，而基于数据的正则化方法则关键地<u>依赖数据</u>。</p>
<h2 id="Convolutional-neural-networks-CNNs-卷积神经网络（CNN）"><a href="#Convolutional-neural-networks-CNNs-卷积神经网络（CNN）" class="headerlink" title="Convolutional neural networks (CNNs). 卷积神经网络（CNN）"></a>Convolutional neural networks (CNNs). 卷积神经网络（CNN）</h2><p>卷积神经网络是过去十年计算机视觉领域最流行的神经网络架构，已被证明表现出强烈的隐性偏见，有利于图像样信号。这一点通过深度图像先验（DIP）[47]及其变体[13， 19]等研究得到了验证，这些方法在无任何预先训练数据的情况下，在图像相关的线性反问题上取得了显著结果。然而，基于CNN的先验与<u>离散网格状信号表示相关联</u>，不适用于新颖视图合成、求解常微分方程等问题，也无法扩展用于三维断层扫描体积、千兆像素图像或大型点云等<u>超高维信号</u>。</p>
<h2 id="Deep-image-prior-深图像先验"><a href="#Deep-image-prior-深图像先验" class="headerlink" title="Deep image prior. 深图像先验"></a>Deep image prior. 深图像先验</h2><p>神经网络，尤其是卷积神经网络，由于其特定架构（如UNet[37]）表现出隐性偏见，这意味着即使是未经训练的神经网络也可以用于正则化。该技术被用来构建深度图像先验（DIP）[47]，产生输出趋向于图像的效果。虽然DIP在正则化方面优于解析方法，但<u>通常只有在参数过大且与类似网格的离散信号表示绑定时表现良好，这意味着DIP无法扩展到高维信号</u>，如点云，且点数众多。深度解码器[19]和DeepTensor[38]在一定程度上解决了计算成本问题，但仍需将信号定义为<u>规则数据网格</u>，如二维矩阵或三维张量。</p>
<h2 id="Implicit-representations-隐式表示"><a href="#Implicit-representations-隐式表示" class="headerlink" title="Implicit representations. 隐式表示"></a>Implicit representations. 隐式表示</h2><p>INR是基于多层感知器（MLP）的连续学习函数近似器。INR的连续性在处理点云等不规则采样信号时尤为吸引人。自从首次广泛应用于图形学的新颖视图合成[27]以来，INR几乎渗透到所有视觉和信号处理领域，包括渲染[22]、计算成像[5， 11]、医学成像[49]和虚拟现实[14]。</p>
<p>在标准神经网络中，ReLU 非线性被普遍采用，实证显示其在 INR 中近似准确率较低。这一问题通过对 MLP 的多项修改得到解决，包括所谓的位置编码[28， 43]，以及各种非线性选择，如正弦函数[41]和高斯函数[33]。一项密切相关的工作是基于加博尔小波的乘法滤波器网络（MFN），其中每层后的输出与加博尔滤波器相乘。输出结果是指数级数量的加博尔小波组合，从而产生了大容量。还提出了许多架构变革，利用视觉信号的多尺度特性加速INR训练过程，包括自适应块分解[25]、千NeRF[34]以及信号的拉普拉斯金字塔预测[39]。</p>
<p>得益于这些众多进展，INR现在<em><strong>几乎可以即时训练信号</strong></em>[28]。然而，此类INR的高ca流动性排除了鲁棒性——这意味着信号表示较脆，导致对噪声和信号的过度拟合。本文提出复Gabor小波作为非线性，该小波独特地适合诱导INR的鲁棒性。</p>
<h2 id="Wavelet-transform-and-the-Gabor-wavelet-小波变换和加博尔小波"><a href="#Wavelet-transform-and-the-Gabor-wavelet-小波变换和加博尔小波" class="headerlink" title="Wavelet transform and the Gabor wavelet. 小波变换和加博尔小波"></a>Wavelet transform and the Gabor wavelet. 小波变换和加博尔小波</h2><p>傅里叶变换将信号分解为具有无限空间支撑的正弦波和，这意味着不存在空间紧致性。</p>
<p>小波变换通过将信号分解为**<u>平移和缩放版本的线性组合</u>**，称为短振荡脉冲，从而解决了这个问题。</p>
<p>小波通常比傅里叶变换更快的信号和图像近似速率[15]，因此常用于图像压缩[16， 40]，并作为图像逆问题[18]和视频[48]的稳健先验[48]。本文展示了小波因其在空间和频率上的紧凑支持，因此具有更快速的近似速率，是INR非线性的普遍优选。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://chuyunnn.github.io">chuyun deng</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://chuyunnn.github.io/papers/work1/WIRE-Wavelet-Implicit-Neural-Representations/">https://chuyunnn.github.io/papers/work1/WIRE-Wavelet-Implicit-Neural-Representations/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/INR/">INR</a><a class="post-meta__tags" href="/tags/SR/">SR</a><a class="post-meta__tags" href="/tags/papers/">papers</a></div><div class="post-share"><div class="social-share" data-image="/img/butterfly-icon.png" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%BC%80%E5%8F%91/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" title="消息队列"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">消息队列</div></div><div class="info-2"><div class="info-item-1">模式消息队列的模式：消息从生产者发送到队列，再由消费者接收处理的规则和链路设计，核心解决一条消息该被谁接收、接收几次、怎么分配的问题，是消息队列的核心设计逻辑之一 点对点模式（多个）生产者发送消息到专属的消息队列，多个消费者可以监听同一个队列，但⚠️一条消息只能被其中一个消费者接收并处理一次⚠️，处理完成后消息会从队列中删除  通过队列实现解耦：生产者直接面向队列发消息，消费者直接面向队列收消息，互不感知  负载均衡：多个消费者监听同一队列时，队列会把消息均匀分配给不同消费者（比如轮询、按消费能力分配），实现任务分流  消息可持久化：未被消费的消息会存在队列中，消费者下线后重启仍能继续消费，不会丢失    消费者处理一个消息失败 &#x3D;&#x3D;&gt; 消息放回队列，其他的消费者可以继续处理（重发而不是多消费）  典型实现RabbitMQ 的简单队列 &#x2F; 工作队列、ActiveMQ 的 P2P 队列、Kafka 的单分区消费（单分区等价于 P2P） 发布-订阅模式生产者发送消息到主题（不是直接发送到队列） 消费者需要先订阅这个主题，消息队列会为每个订阅者创建专...</div></div></div></a><a class="pagination-related" href="/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%BC%80%E5%8F%91/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/" title="定时任务"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">定时任务</div></div><div class="info-2"><div class="info-item-1">定时任务就是让系统在指定的时间或按照一定的周期自动执行某个任务，不需要人工触发  比如每天凌晨自动备份数据、每隔 10 分钟检查一次订单状态等  因为有这些任务：  自动执行，不需要人一直盯着。 在特定时间执行，比如凌晨访问量低时做统计 周期性执行，比如每小时同步一次数据 保证任务执行的准确性和及时性，避免人工操作的遗漏或延迟  所以需要引入定时任务。也就是说，它可以用于：  数据备份、日志清理、数据同步、定时发送、超时关闭、缓存刷新、系统状态监控  实例：使用@Scheduled注解实现定时任务123456789/** * 采用定时器方案，每天5:15分刷新站点地图，确保数据的一致性 */@Scheduled(cron = &quot;0 15 5 * * ?&quot;)public void autoRefreshCache() &#123;    log.info(&quot;开始刷新sitemap.xml的url地址，避免出现数据不一致问题!&quot;);    refreshSitemap();    log.info(&quot;刷新完成！&quot;);&#12...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/papers/work1/Diffusion-over-%E9%9A%90%E5%BC%8F%E7%A5%9E%E7%BB%8F%E8%A1%A8%E7%A4%BAINR/" title="Diffusion over 隐式神经表示INR"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-18</div><div class="info-item-2">Diffusion over 隐式神经表示INR</div></div><div class="info-2"><div class="info-item-1">问题表述使用 **神经网络表示函数 φ(x)**。  **φ(x)**：学习一个函数本身。该函数需要满足某些物理 &#x2F; 几何 &#x2F; 数学约束（方程）。  约束：φ 及其导数必须满足某个条件 C &#x3D; 0 这对应于一种 隐式问题表述。   例如，给定一阶导数约束： 1∇φ(x) = f(x)  可以等价地写成如下隐式形式： 1C(x, φ, ∇φ, ∇²φ) = ∇²φ(x) − f(x) = 0  其中x 表示空间坐标，φ(x) 表示 RSS，C 表示规则检查器。当 C &#x3D; 0 时，函数 φ 被认为是合法的。 这里 φ 不是通过显式公式计算得到的，而是由一组“规则”所定义和约束的。 因此，INR 不是一个回归问题，而是一个：寻找合法函数的问题  （合法函数 &#x3D; 满足所有约束条件的解）  在一组约束中： 1C_m(a(x), φ(x), ∇φ(x), ∇²φ(x), …)  寻找一个函数 φ满足m 条规则。不同规则的形式可能不同：  有的只依赖 ∇φ(x) 有的只依赖 ∇²φ(x) 有的还需要外部已知量 a(x)  其中已知条件（PDE）...</div></div></div></a><a class="pagination-related" href="/papers/work2/papers/work2/postpapers-work2-Frequency-Domain-Based-Diffusion-Model-for-Unpaired-Image-Dehazing/" title="&quot;Frequency Domain-Based Diffusion Model for Unpaired Image&quot; Dehazing"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-16</div><div class="info-item-2">&quot;Frequency Domain-Based Diffusion Model for Unpaired Image&quot; Dehazing</div></div><div class="info-2"><div class="info-item-1">基于频域的非配对图像去雾扩散模型 图像去雾：从被雾霾遮挡的图像中恢复清晰图像。传统方法多依赖物理模型（如大气散射模型）或配对训练数据（清晰图像 + 对应雾图像）。  输入：雾图像（Hazy Image） 输出：去雾图像（Dehazed&#x2F;Clear Image） 目标：恢复清晰图像的颜色、纹理和结构，同时去除雾霾造成的衰减和颜色偏移。在非配对设置下，你 不需要每个雾图像都对应一个清晰图像，训练数据更灵活： 数据集只提供一组雾图像和一组清晰图像，但没有逐一对应关系。 通常使用 生成对抗网络（GAN） 或 对比学习（Contrastive Learning） 来学习域间映射： 雾域 → 清晰域 保持图像内容不变，但去除雾霾特征“忽略了频域的雾霾特性（雾霾相关的退化主要表现在幅度谱上）”，这就涉及 图像频域分析：   雾霾对图像主要表现为 低频衰减、高频模糊： 幅度谱的低频部分（整体亮度和大结构）会被衰减或偏移 高频部分（纹理、边缘）会模糊基于对比学习的主流方法如果只在 空间域（RGB像素或特征图） 对比，可能会 保留雾霾残余 或破坏纹理。     abstruct非配对图像去...</div></div></div></a><a class="pagination-related" href="/%E4%BB%93%E5%BA%93/%E6%96%87%E7%AB%A0%E6%95%B4%E7%90%86/" title="文章整理"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-19</div><div class="info-item-2">文章整理</div></div><div class="info-2"><div class="info-item-1">IEEE Communications Surveys &amp; Tutorials 调研 – RM                序号 名称 期刊&#x2F;会议 年份 网络结构 代码地址 补充 参数量 引用量 notes   1 A Tutorial on Environment-Aware Communications via Channel Knowledge Map for 6G IEEE Communications Surveys &amp; Tutorials 2024   曾勇老师的文章   环境感知的CKM               2 Survey on Near-Space Information Networks: Channel Modeling, Transmission, and Networking Perspectives IEEE Communications Surveys &amp; Tutorials ( Early Access ) 2025   分析了高空（无人机）和近地空间的信道建模方法区别      3 Terahertz ...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">chuyun deng</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">38</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">34</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">10</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#abstruct"><span class="toc-number">1.</span> <span class="toc-text">abstruct</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#introduction"><span class="toc-number">2.</span> <span class="toc-text">introduction</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#prior-work"><span class="toc-number">3.</span> <span class="toc-text">prior work</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Regularization-for-inverse-problems-%E9%80%86%E9%97%AE%E9%A2%98%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">3.1.</span> <span class="toc-text">Regularization for inverse problems. 逆问题的正则化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Convolutional-neural-networks-CNNs-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88CNN%EF%BC%89"><span class="toc-number">3.2.</span> <span class="toc-text">Convolutional neural networks (CNNs). 卷积神经网络（CNN）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Deep-image-prior-%E6%B7%B1%E5%9B%BE%E5%83%8F%E5%85%88%E9%AA%8C"><span class="toc-number">3.3.</span> <span class="toc-text">Deep image prior. 深图像先验</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Implicit-representations-%E9%9A%90%E5%BC%8F%E8%A1%A8%E7%A4%BA"><span class="toc-number">3.4.</span> <span class="toc-text">Implicit representations. 隐式表示</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Wavelet-transform-and-the-Gabor-wavelet-%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2%E5%92%8C%E5%8A%A0%E5%8D%9A%E5%B0%94%E5%B0%8F%E6%B3%A2"><span class="toc-number">3.5.</span> <span class="toc-text">Wavelet transform and the Gabor wavelet. 小波变换和加博尔小波</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%BC%80%E5%8F%91/ping/" title="ping">ping</a><time datetime="2026-01-30T08:36:50.000Z" title="Created 2026-01-30 16:36:50">2026-01-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%BC%80%E5%8F%91/websocket/" title="websocket">websocket</a><time datetime="2026-01-30T08:16:09.000Z" title="Created 2026-01-30 16:16:09">2026-01-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%BC%80%E5%8F%91/HTTP-HTTPs/" title="HTTP-HTTPs">HTTP-HTTPs</a><time datetime="2026-01-30T06:49:42.000Z" title="Created 2026-01-30 14:49:42">2026-01-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%BC%80%E5%8F%91/%E6%89%AB%E7%A0%81%E7%99%BB%E5%BD%95/" title="扫码登录">扫码登录</a><time datetime="2026-01-29T12:25:25.000Z" title="Created 2026-01-29 20:25:25">2026-01-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%BC%80%E5%8F%91/%E8%80%97%E6%97%B6%E7%BB%9F%E8%AE%A1/" title="耗时统计">耗时统计</a><time datetime="2026-01-29T07:12:01.000Z" title="Created 2026-01-29 15:12:01">2026-01-29</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 - 2026 By chuyun deng</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.3"></script><script src="/js/main.js?v=5.5.3"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>