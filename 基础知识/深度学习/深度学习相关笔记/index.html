<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="优化器Adam : Adaptive Moment Estimation特点：  自适应学习率：每个参数都有自己的学习率 带偏差修正：初期收敛更稳定  缺点：正则化效果不好，L2 weight decay 实际上是“对梯度加衰减”，不是真正正则化参数 AdamW : Adam + 正确的 Weight DecayAdam 里 L2 weight decay 是和梯度混合的 → 实际上是“修改梯度”">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习相关笔记">
<meta property="og:url" content="http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="优化器Adam : Adaptive Moment Estimation特点：  自适应学习率：每个参数都有自己的学习率 带偏差修正：初期收敛更稳定  缺点：正则化效果不好，L2 weight decay 实际上是“对梯度加衰减”，不是真正正则化参数 AdamW : Adam + 正确的 Weight DecayAdam 里 L2 weight decay 是和梯度混合的 → 实际上是“修改梯度”">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2025/png/43477865/1755762479006-ab828de1-3dc7-4fad-9327-dab99dafcd7d.png">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2025/png/43477865/1755762645469-16b1b6a4-71fd-4f9a-8a78-63dbd36f91cc.png">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2025/png/43477865/1755762655635-aef8ef3d-d598-41ff-9afb-461676412929.png">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2025/png/43477865/1755762737290-85e5c74d-7817-42de-a5b2-d347ee65f344.png">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2025/png/43477865/1755762828361-89f32c21-0ada-47d1-bca1-5d440b187c32.png">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2025/png/43477865/1755764785214-2fd7974e-ede8-43fd-9c3d-f632bf52c1b4.png">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2025/png/43477865/1755764792166-8ac78112-4cd1-4458-9d27-e633e0b53f70.png">
<meta property="article:published_time" content="2026-01-16T09:27:55.000Z">
<meta property="article:modified_time" content="2026-01-16T09:30:02.696Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="notes">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.nlark.com/yuque/0/2025/png/43477865/1755762479006-ab828de1-3dc7-4fad-9327-dab99dafcd7d.png">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>深度学习相关笔记</title>
    <!-- async scripts -->
    <!-- Google Analytics -->


    <!-- Umami Analytics -->


    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
<meta name="generator" content="Hexo 7.3.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa-solid fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="http://github.com/probberechts">Projects</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/papers/conclusion/%E6%96%87%E7%AB%A0%E6%80%BB%E7%BB%93/"><i class="fa-solid fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/radio-map-dataset/%E6%95%B0%E6%8D%AE%E9%9B%86/"><i class="fa-solid fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fa-solid fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/&text=深度学习相关笔记"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/&title=深度学习相关笔记"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/&is_video=false&description=深度学习相关笔记"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=深度学习相关笔记&body=Check out this article: http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/"><i class="fa-solid fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/&title=深度学习相关笔记"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/&title=深度学习相关笔记"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/&title=深度学习相关笔记"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/&title=深度学习相关笔记"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/&name=深度学习相关笔记&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/&t=深度学习相关笔记"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    
    
      <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">1.</span> <span class="toc-text">优化器</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Adam-Adaptive-Moment-Estimation"><span class="toc-number">1.1.</span> <span class="toc-text">Adam : Adaptive Moment Estimation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AdamW-Adam-%E6%AD%A3%E7%A1%AE%E7%9A%84-Weight-Decay"><span class="toc-number">1.2.</span> <span class="toc-text">AdamW : Adam + 正确的 Weight Decay</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LAMB-Layer-wise-Adaptive-Moments-optimizer-for-Batch-training-%E4%B8%BA%E5%A4%A7-batch-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E8%AE%BE%E8%AE%A1%E7%9A%84-AdamW-%E5%8F%98%E4%BD%93"><span class="toc-number">1.3.</span> <span class="toc-text">LAMB : Layer-wise Adaptive Moments optimizer for Batch training &#x3D;&#x3D;&gt; 为大 batch &#x2F; 大模型训练设计的 AdamW 变体</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%EF%BC%9A"><span class="toc-number">1.4.</span> <span class="toc-text">总结：</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">2.</span> <span class="toc-text">正则化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#L2-%E6%AD%A3%E5%88%99%EF%BC%88Ridge-Weight-Decay%EF%BC%89"><span class="toc-number">2.1.</span> <span class="toc-text">L2 正则（Ridge &#x2F; Weight Decay）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#L1-%E6%AD%A3%E5%88%99%EF%BC%88Lasso%EF%BC%89"><span class="toc-number">2.2.</span> <span class="toc-text">L1 正则（Lasso）</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A1%A5%E5%85%85%EF%BC%9A"><span class="toc-number">3.</span> <span class="toc-text">补充：</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E6%95%B0-%E6%A2%AF%E5%BA%A6-%E6%9D%83%E9%87%8D-%E5%AD%A6%E4%B9%A0%E7%8E%87"><span class="toc-number">3.1.</span> <span class="toc-text">参数 梯度 权重 学习率</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8%E4%B8%AD%E7%9A%84weight-decay"><span class="toc-number">3.2.</span> <span class="toc-text">优化器中的weight decay</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8%E4%B8%AD%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">3.3.</span> <span class="toc-text">优化器中的正则化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9D%83%E9%87%8D%EF%BC%88%E5%8F%82%E6%95%B0%EF%BC%89%E6%9B%B4%E6%96%B0"><span class="toc-number">3.4.</span> <span class="toc-text">权重（参数）更新</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E7%A7%8D%E5%AD%90"><span class="toc-number">4.</span> <span class="toc-text">随机种子</span></a></li></ol>
      </div>
    
  </span>
</div>

    
    <div class="content index py4 ">
        
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle p-name" itemprop="name headline">
        深度学习相关笔记
    </h1>



    <div class="meta">
      <span class="author p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span class="p-name" itemprop="name">John Doe</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2026-01-16T09:27:55.000Z" class="dt-published" itemprop="datePublished">2026-01-16</time>
        
      
    </div>


      
    <div class="article-category">
        <i class="fa-solid fa-archive"></i>
        <a class="category-link" href="/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">基础知识</a> › <a class="category-link" href="/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
    </div>


      
    <div class="article-tag">
        <i class="fa-solid fa-tag"></i>
        <a class="p-category" href="/tags/notes/" rel="tag">notes</a>
    </div>


    </div>
  </header>
  

  <div class="content e-content" itemprop="articleBody">
    <h1 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h1><h2 id="Adam-Adaptive-Moment-Estimation"><a href="#Adam-Adaptive-Moment-Estimation" class="headerlink" title="Adam : Adaptive Moment Estimation"></a>Adam : <strong>Adaptive Moment Estimation</strong></h2><p><strong>特点：</strong></p>
<ul>
<li><strong>自适应学习率</strong>：<strong>每个参数都有自己的学习率</strong></li>
<li><strong>带偏差修正</strong>：初期收敛更稳定</li>
</ul>
<p><strong>缺点</strong>：正则化效果不好，L2 weight decay 实际上是“<strong>对梯度加衰减</strong>”，<strong>不是真正正则化参数</strong></p>
<h2 id="AdamW-Adam-正确的-Weight-Decay"><a href="#AdamW-Adam-正确的-Weight-Decay" class="headerlink" title="AdamW : Adam + 正确的 Weight Decay"></a>AdamW : <strong>Adam + 正确的 Weight Decay</strong></h2><p>Adam 里 <strong>L2 weight decay 是和梯度混合的</strong> → 实际上是“修改梯度”，容易影响动量</p>
<p>&#x3D;&#x3D;&gt; AdamW 把 weight decay <strong>独立应用在参数更新上</strong></p>
<p>优点：</p>
<ul>
<li><strong>正则化更纯粹</strong> → 提高泛化能力</li>
<li><strong>训练更稳定</strong> → 常用于 Transformer 和大模型</li>
</ul>
<p>💡 总结一句话：<strong>AdamW 就是带正确 L2 正则的 Adam</strong></p>
<h2 id="LAMB-Layer-wise-Adaptive-Moments-optimizer-for-Batch-training-为大-batch-大模型训练设计的-AdamW-变体"><a href="#LAMB-Layer-wise-Adaptive-Moments-optimizer-for-Batch-training-为大-batch-大模型训练设计的-AdamW-变体" class="headerlink" title="LAMB : Layer-wise Adaptive Moments optimizer for Batch training &#x3D;&#x3D;&gt; 为大 batch &#x2F; 大模型训练设计的 AdamW 变体"></a><strong>LAMB : Layer-wise Adaptive Moments optimizer for Batch training &#x3D;&#x3D;&gt; 为大 batch &#x2F; 大模型训练设计的 AdamW 变体</strong></h2><ul>
<li><strong>Layer-wise 自适应缩放:</strong> 每一层的参数更新 \Delta \theta <strong>按比例缩放</strong></li>
</ul>
<p>&#x3D;&#x3D;&gt; 解决大 batch 时学习率不均衡的问题</p>
<ul>
<li><strong>保留 AdamW 的优点</strong>：偏差修正 + weight decay 独立</li>
</ul>
<p>特点：</p>
<ul>
<li><strong>适合大 batch 训练</strong>（比如 BERT 或 GPT 大模型训练）</li>
<li><strong>学习率可以更大</strong>，收敛稳定</li>
<li>对小模型、小 batch 不一定比 AdamW 有优势</li>
</ul>
<p><strong>Adam&#x2F;SGD 的问题</strong>：在大 batch 训练时，直接放大学习率会导致震荡甚至不收敛。</p>
<p><strong>LAMB 的改进</strong>：</p>
<ol>
<li>它不仅像 Adam 一样对梯度做自适应缩放，还对 <strong>参数本身的范数</strong> 做归一化。</li>
<li>换句话说，它确保“更新步长”和“参数大小”是成比例的，避免某些参数更新过大&#x2F;过小。</li>
</ol>
<p>这让 <strong>大 batch 训练时依然能稳定收敛</strong>，并且允许用更大学习率，加速训练</p>
<h2 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h2><p><img src="https://cdn.nlark.com/yuque/0/2025/png/43477865/1755762479006-ab828de1-3dc7-4fad-9327-dab99dafcd7d.png" alt="img"></p>
<p>优化器会动态调整 <strong>步长（学习率）</strong>：</p>
<ul>
<li><strong>SGD</strong>：固定学习率，单纯往梯度方向走。</li>
<li><strong>Adam</strong>：用一阶（均值）和二阶（方差）矩估计，对每个参数自适应调节学习率（大梯度 → 缩小步长，小梯度 → 放大学习率）。</li>
<li><strong>AdamW</strong>：在 Adam 基础上修正 weight decay 逻辑，让正则化效果更纯粹。</li>
<li><strong>学习率调度器（Scheduler）</strong>：额外定义随训练过程变化的学习率（warmup、cosine decay 等）。</li>
</ul>
<h1 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h1><p>定义：在模型训练时，加上一个约束，让它不要随意拟合训练数据，从而提高泛化能力。</p>
<ul>
<li>没正则化 → 模型可能过拟合 → 在训练集上很好，但测试集上表现差</li>
<li>正则化 → 给模型“穿上枷锁”，让它学到<strong>更平滑、更简单的规律</strong></li>
</ul>
<p>数学解释：在原本的损失函数上添加一个惩罚项<img src="https://cdn.nlark.com/yuque/0/2025/png/43477865/1755762645469-16b1b6a4-71fd-4f9a-8a78-63dbd36f91cc.png" alt="img"><img src="https://cdn.nlark.com/yuque/0/2025/png/43477865/1755762655635-aef8ef3d-d598-41ff-9afb-461676412929.png" alt="img"></p>
<h2 id="L2-正则（Ridge-Weight-Decay）"><a href="#L2-正则（Ridge-Weight-Decay）" class="headerlink" title="L2 正则（Ridge &#x2F; Weight Decay）"></a><strong>L2 正则（Ridge &#x2F; Weight Decay）</strong></h2><p>公式：</p>
<p><img src="https://cdn.nlark.com/yuque/0/2025/png/43477865/1755762737290-85e5c74d-7817-42de-a5b2-d347ee65f344.png" alt="img"></p>
<p>特点：</p>
<ul>
<li>惩罚参数的平方 → 大参数会被压小</li>
<li>对所有参数平滑地缩小 → 模型参数分布更均匀</li>
<li>在优化器里对应 <strong>weight decay</strong></li>
</ul>
<p>直观理解：</p>
<ul>
<li>想象每个参数是一根弹簧，L2 惩罚让弹簧尽量不要伸得太长</li>
<li>模型<strong>不敢过度依赖某个特征</strong> → 泛化能力强</li>
</ul>
<p><strong>为什么大参数被压缩，模型不依赖单个特征？</strong></p>
<ul>
<li>假设某个特征的权重大 → 它在预测中起决定性作用</li>
<li>L2 正则会把所有权重都缩小 → 大权重被拉小 → 模型不能只依赖它</li>
</ul>
<p>结果：</p>
<ul>
<li>模型分布在更多参数上 → <strong>特征利用更均衡</strong></li>
<li>泛化能力提升，不会因为训练集某个特征异常而过拟合</li>
</ul>
<h2 id="L1-正则（Lasso）"><a href="#L1-正则（Lasso）" class="headerlink" title="L1 正则（Lasso）"></a><strong>L1 正则（Lasso）</strong></h2><p>公式：</p>
<p><img src="https://cdn.nlark.com/yuque/0/2025/png/43477865/1755762828361-89f32c21-0ada-47d1-bca1-5d440b187c32.png" alt="img"></p>
<p>特点：</p>
<ul>
<li>惩罚参数绝对值</li>
<li>会产生 <strong>稀疏解</strong> → 很多参数被压到 0</li>
<li>可以做特征选择：保留重要特征，忽略不重要特征</li>
</ul>
<p>直观理解：</p>
<ul>
<li>想象把每根参数的长度直接砍掉一部分 → 不重要的直接砍成 0</li>
</ul>
<p>特点：</p>
<ul>
<li>梯度在 0 附近不连续 → 很容易把小参数直接压为 0</li>
<li>重要参数保留 → 0 的参数对应“不重要”特征被忽略</li>
</ul>
<p>所以：</p>
<ul>
<li><strong>稀疏解 &#x3D; 自动选择特征</strong></li>
<li>模型只保留对预测贡献大的特征</li>
</ul>
<h1 id="补充："><a href="#补充：" class="headerlink" title="补充："></a>补充：</h1><h2 id="参数-梯度-权重-学习率"><a href="#参数-梯度-权重-学习率" class="headerlink" title="参数 梯度 权重 学习率"></a>参数 梯度 权重 学习率</h2><ol>
<li><strong>权重（weight）</strong>：就是模型里的参数。</li>
</ol>
<p>模型学习的核心目标就是找到一组最优权重，使得预测结果和真实标签尽可能接近。</p>
<ol>
<li><strong>梯度（gradient）</strong>：损失函数对权重的导数（往哪走）</li>
</ol>
<p>它告诉我们：如果我稍微调整某个权重，损失会往哪个方向增大&#x2F;减小。</p>
<p>所以梯度本质上是<strong>更新权重的方向指引器</strong>，而不是权重本身。</p>
<ol>
<li><strong>学习率</strong>：控制“步长”，在梯度更新和正则化中都起作用（走的步长）</li>
</ol>
<p>控制梯度下降和正则化压缩的步长</p>
<p><strong>学习率衰减：</strong>随训练逐步减小 \eta</p>
<ul>
<li><p>初期大步 → 快速下降</p>
</li>
<li><p>后期小步 → 收敛稳定</p>
</li>
<li><p>作用于梯度和正则化一起，避免收敛振荡</p>
</li>
</ul>
<p>梯度下降：根据梯度调整参数</p>
<p>正则化：在损失函数中加上了一项，求导之后权重更新中多了一项正则项对梯度的贡献</p>
<p>weight decay：不从梯度计算，直接对参数进行衰减 &#x3D;&#x3D;&gt; 避免和动量&#x2F;自适应梯度混合干扰，数值表现更稳定（这就是 AdamW 的核心改进 –&gt; 把两者区分开）。</p>
<h2 id="优化器中的weight-decay"><a href="#优化器中的weight-decay" class="headerlink" title="优化器中的weight decay"></a>优化器中的weight decay</h2><p><strong>Weight Decay</strong> 就是 <strong>L2 正则化在优化器里的实现方式</strong></p>
<p>传统做法：在更新参数的时候直接加上对参数的惩罚</p>
<p><img src="https://cdn.nlark.com/yuque/0/2025/png/43477865/1755764785214-2fd7974e-ede8-43fd-9c3d-f632bf52c1b4.png" alt="img"></p>
<p><img src="https://cdn.nlark.com/yuque/0/2025/png/43477865/1755764792166-8ac78112-4cd1-4458-9d27-e633e0b53f70.png" alt="img"></p>
<h2 id="优化器中的正则化"><a href="#优化器中的正则化" class="headerlink" title="优化器中的正则化"></a>优化器中的正则化</h2><p><strong>通常只有 L2（Weight Decay）。</strong>L1 可以自己手动加到损失函数里，但主流优化器（AdamW、LAMB、SGD）默认只支持 L2&#x2F;Weight Decay</p>
<p>有些场景会混合使用（比如 Elastic Net &#x3D; L1 + L2）</p>
<h2 id="权重（参数）更新"><a href="#权重（参数）更新" class="headerlink" title="权重（参数）更新"></a>权重（参数）更新</h2><p>权重（参数）更新是 <strong>梯度 + 正则化 + 优化器机制</strong> 共同作用的结果：</p>
<ul>
<li><strong>梯度</strong>：来自损失函数 \mathcal{L}，告诉你该往哪走、走多远（方向 + 大小）。</li>
<li><strong>正则化</strong>：相当于在损失函数里加“惩罚项”，<strong>限制参数规模或稀疏化</strong>（L1&#x2F;L2），避免模型太复杂。</li>
<li><strong>优化器</strong>：在用梯度更新参数时，额外引入技巧（动量、学习率调度、权重衰减等），让训练更快、更稳。</li>
</ul>
<p>你可以把它想成：<strong>梯度是指路灯，正则化是修路时加的护栏，优化器是导航软件，三者一起决定你怎么走到终点。</strong></p>
<h1 id="随机种子"><a href="#随机种子" class="headerlink" title="随机种子"></a>随机种子</h1><p>在深度学习里很多东西都带“随机性”：</p>
<ul>
<li><strong>数据打乱</strong>（shuffle&#x3D;True 时，每个 epoch 样本顺序会随机变化）</li>
<li><strong>参数初始化</strong>（模型的权重通常用随机数初始化）</li>
<li><strong>Dropout</strong>（每次会随机丢掉不同的神经元）</li>
<li><strong>数据增强</strong>（随机裁剪、翻转等）</li>
</ul>
<p>如果不设种子，每次运行都会不一样，结果可能波动很大。</p>
<p><strong>&#x3D;&#x3D;&gt; 设定随机种子 &#x3D; 固定“随机数生成器”的起点</strong>，保证你下次跑出来的结果和这次一样（复现实验）。</p>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
        
          <li><a href="/">Home</a></li>
        
          <li><a href="/about/">About</a></li>
        
          <li><a href="/archives/">Writing</a></li>
        
          <li><a target="_blank" rel="noopener" href="http://github.com/probberechts">Projects</a></li>
        
      </ul>
    </div>

    
    
      <div id="toc-footer" style="display: none">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">1.</span> <span class="toc-text">优化器</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Adam-Adaptive-Moment-Estimation"><span class="toc-number">1.1.</span> <span class="toc-text">Adam : Adaptive Moment Estimation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AdamW-Adam-%E6%AD%A3%E7%A1%AE%E7%9A%84-Weight-Decay"><span class="toc-number">1.2.</span> <span class="toc-text">AdamW : Adam + 正确的 Weight Decay</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LAMB-Layer-wise-Adaptive-Moments-optimizer-for-Batch-training-%E4%B8%BA%E5%A4%A7-batch-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E8%AE%BE%E8%AE%A1%E7%9A%84-AdamW-%E5%8F%98%E4%BD%93"><span class="toc-number">1.3.</span> <span class="toc-text">LAMB : Layer-wise Adaptive Moments optimizer for Batch training &#x3D;&#x3D;&gt; 为大 batch &#x2F; 大模型训练设计的 AdamW 变体</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%EF%BC%9A"><span class="toc-number">1.4.</span> <span class="toc-text">总结：</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">2.</span> <span class="toc-text">正则化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#L2-%E6%AD%A3%E5%88%99%EF%BC%88Ridge-Weight-Decay%EF%BC%89"><span class="toc-number">2.1.</span> <span class="toc-text">L2 正则（Ridge &#x2F; Weight Decay）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#L1-%E6%AD%A3%E5%88%99%EF%BC%88Lasso%EF%BC%89"><span class="toc-number">2.2.</span> <span class="toc-text">L1 正则（Lasso）</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A1%A5%E5%85%85%EF%BC%9A"><span class="toc-number">3.</span> <span class="toc-text">补充：</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E6%95%B0-%E6%A2%AF%E5%BA%A6-%E6%9D%83%E9%87%8D-%E5%AD%A6%E4%B9%A0%E7%8E%87"><span class="toc-number">3.1.</span> <span class="toc-text">参数 梯度 权重 学习率</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8%E4%B8%AD%E7%9A%84weight-decay"><span class="toc-number">3.2.</span> <span class="toc-text">优化器中的weight decay</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8%E4%B8%AD%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">3.3.</span> <span class="toc-text">优化器中的正则化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9D%83%E9%87%8D%EF%BC%88%E5%8F%82%E6%95%B0%EF%BC%89%E6%9B%B4%E6%96%B0"><span class="toc-number">3.4.</span> <span class="toc-text">权重（参数）更新</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E7%A7%8D%E5%AD%90"><span class="toc-number">4.</span> <span class="toc-text">随机种子</span></a></li></ol>
      </div>
    

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/&text=深度学习相关笔记"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/&title=深度学习相关笔记"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/&is_video=false&description=深度学习相关笔记"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=深度学习相关笔记&body=Check out this article: http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/"><i class="fa-solid fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/&title=深度学习相关笔记"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/&title=深度学习相关笔记"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/&title=深度学习相关笔记"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/&title=深度学习相关笔记"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/&name=深度学习相关笔记&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0/&t=深度学习相关笔记"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fa-solid fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
          <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fa-solid fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fa-solid fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2016-2026
    John Doe
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="http://github.com/probberechts">Projects</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script>




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script>
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="fa-regular fa-clone"></i>';
    btn += '</span>';
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

</body>
</html>
